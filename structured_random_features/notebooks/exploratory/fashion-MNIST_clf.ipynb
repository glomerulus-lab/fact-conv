{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_fns import load_fashion_mnist\n",
    "from estimator import RFClassifier, classical_weights, V1_inspired_weights, relu, parallelized_clf\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39105</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>6</li>\n",
       "  <li><b>Cores: </b>36</li>\n",
       "  <li><b>Memory: </b>67.32 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:39105' processes=6 threads=36, memory=67.32 GB>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "client = Client(threads_per_worker=6, n_workers=6)\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the right params via a parameter sweep with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=0.10, l=0.10\n",
      "Iter: 1/1001, V1 test err=0.84, RF test err= 0.87\n",
      "Iter: 51/1001, V1 test err=0.47, RF test err= 0.43\n",
      "Iter: 101/1001, V1 test err=0.42, RF test err= 0.34\n",
      "Iter: 151/1001, V1 test err=0.37, RF test err= 0.33\n",
      "Iter: 201/1001, V1 test err=0.36, RF test err= 0.30\n",
      "Iter: 251/1001, V1 test err=0.31, RF test err= 0.30\n",
      "Iter: 301/1001, V1 test err=0.30, RF test err= 0.28\n",
      "Iter: 351/1001, V1 test err=0.30, RF test err= 0.27\n",
      "Iter: 401/1001, V1 test err=0.29, RF test err= 0.26\n",
      "Iter: 451/1001, V1 test err=0.28, RF test err= 0.25\n",
      "Iter: 501/1001, V1 test err=0.27, RF test err= 0.24\n",
      "Iter: 551/1001, V1 test err=0.27, RF test err= 0.23\n",
      "Iter: 601/1001, V1 test err=0.26, RF test err= 0.22\n",
      "Iter: 651/1001, V1 test err=0.26, RF test err= 0.22\n",
      "Iter: 701/1001, V1 test err=0.26, RF test err= 0.22\n",
      "Iter: 751/1001, V1 test err=0.25, RF test err= 0.21\n",
      "Iter: 801/1001, V1 test err=0.24, RF test err= 0.20\n",
      "Iter: 851/1001, V1 test err=0.25, RF test err= 0.20\n",
      "Iter: 901/1001, V1 test err=0.25, RF test err= 0.19\n",
      "Iter: 951/1001, V1 test err=0.24, RF test err= 0.19\n",
      "Iter: 1001/1001, V1 test err=0.24, RF test err= 0.18\n",
      "t=0.10, l=0.60\n",
      "Iter: 1/1001, V1 test err=0.85, RF test err= 0.88\n",
      "Iter: 51/1001, V1 test err=0.49, RF test err= 0.43\n",
      "Iter: 101/1001, V1 test err=0.40, RF test err= 0.36\n",
      "Iter: 151/1001, V1 test err=0.35, RF test err= 0.33\n",
      "Iter: 201/1001, V1 test err=0.36, RF test err= 0.31\n",
      "Iter: 251/1001, V1 test err=0.31, RF test err= 0.29\n",
      "Iter: 301/1001, V1 test err=0.31, RF test err= 0.28\n",
      "Iter: 351/1001, V1 test err=0.29, RF test err= 0.27\n",
      "Iter: 401/1001, V1 test err=0.28, RF test err= 0.26\n",
      "Iter: 451/1001, V1 test err=0.28, RF test err= 0.25\n",
      "Iter: 501/1001, V1 test err=0.27, RF test err= 0.24\n",
      "Iter: 551/1001, V1 test err=0.26, RF test err= 0.23\n",
      "Iter: 601/1001, V1 test err=0.27, RF test err= 0.22\n",
      "Iter: 651/1001, V1 test err=0.26, RF test err= 0.22\n",
      "Iter: 701/1001, V1 test err=0.26, RF test err= 0.21\n",
      "Iter: 751/1001, V1 test err=0.25, RF test err= 0.21\n",
      "Iter: 801/1001, V1 test err=0.25, RF test err= 0.20\n",
      "Iter: 851/1001, V1 test err=0.24, RF test err= 0.20\n",
      "Iter: 901/1001, V1 test err=0.24, RF test err= 0.20\n",
      "Iter: 951/1001, V1 test err=0.25, RF test err= 0.19\n",
      "Iter: 1001/1001, V1 test err=0.24, RF test err= 0.19\n",
      "t=0.10, l=1.10\n",
      "Iter: 1/1001, V1 test err=0.84, RF test err= 0.85\n",
      "Iter: 51/1001, V1 test err=0.47, RF test err= 0.42\n",
      "Iter: 101/1001, V1 test err=0.38, RF test err= 0.37\n",
      "Iter: 151/1001, V1 test err=0.37, RF test err= 0.33\n",
      "Iter: 201/1001, V1 test err=0.34, RF test err= 0.32\n",
      "Iter: 251/1001, V1 test err=0.30, RF test err= 0.29\n",
      "Iter: 301/1001, V1 test err=0.28, RF test err= 0.28\n",
      "Iter: 351/1001, V1 test err=0.29, RF test err= 0.26\n",
      "Iter: 401/1001, V1 test err=0.30, RF test err= 0.26\n",
      "Iter: 451/1001, V1 test err=0.28, RF test err= 0.25\n",
      "Iter: 501/1001, V1 test err=0.28, RF test err= 0.24\n",
      "Iter: 551/1001, V1 test err=0.28, RF test err= 0.24\n",
      "Iter: 601/1001, V1 test err=0.28, RF test err= 0.24\n",
      "Iter: 651/1001, V1 test err=0.27, RF test err= 0.22\n",
      "Iter: 701/1001, V1 test err=0.26, RF test err= 0.22\n",
      "Iter: 751/1001, V1 test err=0.24, RF test err= 0.21\n",
      "Iter: 801/1001, V1 test err=0.25, RF test err= 0.21\n",
      "Iter: 851/1001, V1 test err=0.25, RF test err= 0.20\n",
      "Iter: 901/1001, V1 test err=0.24, RF test err= 0.19\n",
      "Iter: 951/1001, V1 test err=0.24, RF test err= 0.19\n",
      "Iter: 1001/1001, V1 test err=0.23, RF test err= 0.19\n",
      "t=0.10, l=1.60\n",
      "Iter: 1/1001, V1 test err=0.86, RF test err= 0.86\n",
      "Iter: 51/1001, V1 test err=0.46, RF test err= 0.43\n",
      "Iter: 101/1001, V1 test err=0.40, RF test err= 0.37\n",
      "Iter: 151/1001, V1 test err=0.34, RF test err= 0.32\n",
      "Iter: 201/1001, V1 test err=0.34, RF test err= 0.31\n",
      "Iter: 251/1001, V1 test err=0.33, RF test err= 0.28\n",
      "Iter: 301/1001, V1 test err=0.29, RF test err= 0.28\n",
      "Iter: 351/1001, V1 test err=0.31, RF test err= 0.27\n",
      "Iter: 401/1001, V1 test err=0.29, RF test err= 0.25\n",
      "Iter: 451/1001, V1 test err=0.28, RF test err= 0.23\n"
     ]
    }
   ],
   "source": [
    "train, train_labels, _, _ = load_fashion_mnist('data/fashion_mnist/')\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, train_labels, train_size=0.85, stratify=train_labels, \n",
    "                                          random_state=None)\n",
    "\n",
    "n_features = np.arange(1, 1050, 50)\n",
    "t_list = np.arange(0.1, 10.1, 0.5)\n",
    "l_list = np.arange(0.1, 10.1, 0.5)\n",
    "sgd = SGDClassifier(loss=\"squared_hinge\", alpha=1, max_iter=300, tol=1e-5, shuffle=True, n_jobs=5,\n",
    "                    learning_rate=\"optimal\", early_stopping=True, validation_fraction=0.1, n_iter_no_change=20)\n",
    "b = np.mean(la.norm(X_train, axis=1) / np.sqrt(X_train.shape[1]))\n",
    "    \n",
    "for t in t_list:\n",
    "    for l in l_list:\n",
    "        results = {}\n",
    "        m = np.zeros_like(n_features, dtype='float')\n",
    "        results['classical'] = {'avg_test_err': m.copy(), 'std_test_err': m.copy()}\n",
    "        results['V1'] = {'avg_test_err': m.copy(), 'std_test_err': m.copy()}\n",
    "        \n",
    "        print('t=%0.2f, l=%0.2f' % (t, l))\n",
    "        for i, n in enumerate(n_features):\n",
    "            # classical random features\n",
    "            weights_classical = {'weight_fun': classical_weights}\n",
    "            params_classical = {'width': n, **weights_classical, 'bias': b, 'nonlinearity': relu, 'clf': sgd}\n",
    "            _, _, results['classical']['avg_test_err'][i], results['classical']['std_test_err'][i]= parallelized_clf(RFClassifier, \n",
    "                                                                                                            params_classical, \n",
    "                                                                                                            X_train, y_train, \n",
    "                                                                                                            X_val, y_val, \n",
    "                                                                                                            n_iters=10, return_clf=False)\n",
    "\n",
    "            # haltere inspired\n",
    "            kwargs = {'t': t, 'l': l}\n",
    "            weights_V1 = {'weight_fun': V1_inspired_weights, 'kwargs': kwargs}\n",
    "            params_V1 = {'width': n, **weights_V1, 'bias': b, 'nonlinearity': relu, 'clf': sgd} \n",
    "            _, _, results['V1']['avg_test_err'][i], results['V1']['std_test_err'][i] = parallelized_clf(RFClassifier, \n",
    "                                                                                                        params_V1, \n",
    "                                                                                                        X_train, y_train, \n",
    "                                                                                                        X_val, y_val, \n",
    "                                                                                                        n_iters=10, return_clf=False)\n",
    "            print('Iter: %d/%d, V1 test err=%0.2f, RF test err= %0.2f' % (n, n_features[-1],  \n",
    "                                                                               results['V1']['avg_test_err'][i],\n",
    "                                                                              results['classical']['avg_test_err'][i]))\n",
    "            \n",
    "        with open('results/fashion_mnist_clf/fashion_mnist_clf_t=%0.3f_l=%0.3f_sgd.pickle' % (t, l), 'wb') as handle:\n",
    "            pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X_train, y_train, X_test, y_test = load_fashion_mnist('data/fashion_mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = sorted(set(np.logspace(0, 3.2, 50).astype('int')))\n",
    "\n",
    "# weight params\n",
    "t, l = 5, 1\n",
    "kwargs = {'t': t, 'l': l}\n",
    "weights_V1 = {'weight_fun': V1_inspired_weights, 'kwargs': kwargs}\n",
    "weights_classical = {'weight_fun': classical_weights}\n",
    "\n",
    "# params for classification\n",
    "sgd = SGDClassifier(loss=\"squared_hinge\", alpha=1, max_iter=500, tol=1e-4, shuffle=True, n_jobs=5,\n",
    "                    learning_rate=\"optimal\", early_stopping=True, validation_fraction=0.1, n_iter_no_change=20)\n",
    "svc = LinearSVC(random_state=None, tol=1e-4, max_iter=500)\n",
    "# b = np.mean(la.norm(X_train) / np.sqrt(X_train.shape[0]))\n",
    "b = np.mean(la.norm(X_train, axis=1) / np.sqrt(X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "results = {}\n",
    "m = np.zeros_like(n_features, dtype='float')\n",
    "results['classical'] = {'avg_test_err': m.copy(), 'std_test_err': m.copy()}\n",
    "results['V1'] = {'avg_test_err': m.copy(), 'std_test_err': m.copy()}\n",
    "for i, n in enumerate(n_features):\n",
    "\n",
    "    # classical random features\n",
    "    params_classical = {'width': n, **weights_classical, 'bias': b, 'nonlinearity': relu, 'clf': svc}\n",
    "    _, _, results['classical']['avg_test_err'][i], results['classical']['std_test_err'][i]= parallelized_clf(RFClassifier, \n",
    "                                                                                                    params_classical, \n",
    "                                                                                                    X_train, y_train, \n",
    "                                                                                                    X_test, y_test, \n",
    "                                                                                                    n_iters=5, return_clf=False)\n",
    "    \n",
    "    # haltere inspired\n",
    "    params_V1 = {'width': n, **weights_V1, 'bias': b, 'nonlinearity': relu, 'clf': svc} \n",
    "    _, _, results['V1']['avg_test_err'][i], results['V1']['std_test_err'][i] = parallelized_clf(RFClassifier, \n",
    "                                                                                                params_V1, \n",
    "                                                                                                X_train, y_train, \n",
    "                                                                                                X_test, y_test, \n",
    "                                                                                                n_iters=5, return_clf=False)\n",
    "\n",
    "    print('Iter: %d/%d, V1 test err=%0.2f, RF test err= %0.2f' % (n, n_features[-1],  \n",
    "                                                                       results['V1']['avg_test_err'][i],\n",
    "                                                                      results['classical']['avg_test_err'][i]))\n",
    "    \n",
    "# with open('results/fashion_mnist_clf/fashion_mnist_clf_t=%0.2f_l=%0.2f.pickle' % (t, l), 'wb') as handle:\n",
    "#     pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t, l = 5, 2\n",
    "# with open('results/fashion_mnist_clf/fashion_mnist_clf_t=%0.2f_l=%0.2f.pickle' % (t, l), 'rb') as handle:\n",
    "#     results = pickle.load(handle)\n",
    "    \n",
    "\n",
    "fig = plt.figure(figsize=(10.6, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.errorbar(n_features, results['V1']['avg_test_err'], yerr=results['V1']['std_test_err'], fmt='-', \n",
    "            label='V1-inspired',  markersize=4, lw=5, elinewidth=3)\n",
    "ax.errorbar(n_features, results['classical']['avg_test_err'], yerr=results['classical']['std_test_err'], \n",
    "            fmt='-', label='classical', markersize=4, lw=5, elinewidth=3)\n",
    "plt.xlabel('Hidden layer width', fontsize=40)\n",
    "plt.ylabel('Classification error', fontsize=40)\n",
    "# plt.xticks(np.arange(0, 1020, 200))\n",
    "plt.xlim([0, 1020])\n",
    "plt.yticks(np.arange(0, 0.8, 0.1))\n",
    "plt.ylim([-0.05, 0.55])\n",
    "plt.xticks(np.arange(0, 1020, 200))\n",
    "ax.tick_params(axis = 'both', which = 'major', labelsize = 30, width=2, length=6)\n",
    "\n",
    "plt.legend(loc = 'upper right', fontsize=30)\n",
    "# plt.savefig('results/fashion_mnist_clf/fashion_mnist_clf_t=%0.2f_l=%0.2f.pdf' % (t, l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(n_features, results['V1']['avg_test_err']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(n_features, results['classical']['avg_test_err']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_labels, test, test_labels = load_fashion_mnist('data/fashion_mnist/')\n",
    "num_train = 50\n",
    "X_train, _, y_train, _ = train_test_split(train, train_labels, train_size=num_train, stratify=train_labels, \n",
    "                                          random_state=42)\n",
    "X_test, y_test = test.copy(), test_labels.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = sorted(set(np.logspace(0, 3.2, 50).astype('int')))\n",
    "\n",
    "# weight params\n",
    "t, l = 5, 2\n",
    "kwargs = {'t': t, 'l': l}\n",
    "weights_V1 = {'weight_fun': V1_inspired_weights, 'kwargs': kwargs}\n",
    "weights_classical = {'weight_fun': classical_weights}\n",
    "\n",
    "# params for classification\n",
    "# sgd = SGDClassifier(loss=\"squared_hinge\", alpha=1, max_iter=200, tol=1e-4, shuffle=True, n_jobs=5,\n",
    "#                     learning_rate=\"optimal\", early_stopping=True, validation_fraction=0.1, n_iter_no_change=20)\n",
    "svc = LinearSVC(random_state=20, tol=1e-4, max_iter=500)\n",
    "b = np.mean(la.norm(X_train)/ np.sqrt(X_train.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "results = {}\n",
    "m = np.zeros_like(n_features, dtype='float')\n",
    "results['classical'] = {'avg_test_err': m.copy(), 'std_test_err': m.copy()}\n",
    "results['V1'] = {'avg_test_err': m.copy(), 'std_test_err': m.copy()}\n",
    "for i, n in enumerate(n_features):\n",
    "\n",
    "    # classical random features\n",
    "    params_classical = {'width': n, **weights_classical, 'bias': b, 'nonlinearity': relu, 'clf': svc}\n",
    "    _, _, results['classical']['avg_test_err'][i], results['classical']['std_test_err'][i] = parallelized_clf(RFClassifier, \n",
    "                                                                                                    params_classical, \n",
    "                                                                                                    X_train, y_train, \n",
    "                                                                                                    X_test, y_test, \n",
    "                                                                                                    n_iters=10)\n",
    "    \n",
    "    # haltere inspired\n",
    "    params_V1 = {'width': n, **weights_V1, 'bias': b, 'nonlinearity': relu, 'clf': svc} \n",
    "    _, _, results['V1']['avg_test_err'][i], results['V1']['std_test_err'][i] = parallelized_clf(RFClassifier, \n",
    "                                                                                                params_V1, \n",
    "                                                                                                X_train, y_train, \n",
    "                                                                                                X_test, y_test, \n",
    "                                                                                                n_iters=10)\n",
    "\n",
    "    print('Iter: %d/%d, V1 test err=%0.2f, RF test err= %0.2f' % (n, n_features[-1],  \n",
    "                                                                       results['V1']['avg_test_err'][i],\n",
    "                                                                      results['classical']['avg_test_err'][i]))\n",
    "    \n",
    "with open('results/fashion_mnist_clf/fashion_mnist_clf_t=%0.2f_l=%0.3f_few_shot.pickle' % (t, l), 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10.6, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.errorbar(n_features, results['V1']['avg_test_err'], yerr=results['V1']['std_test_err'], fmt='-', \n",
    "            label='V1-inspired',  markersize=4, lw=5, elinewidth=3)\n",
    "ax.errorbar(n_features, results['classical']['avg_test_err'], yerr=results['classical']['std_test_err'], \n",
    "            fmt='-', label='classical', markersize=4, lw=5, elinewidth=3)\n",
    "plt.xlabel('Hidden layer width', fontsize=40)\n",
    "plt.ylabel('Classification error', fontsize=40)\n",
    "# plt.xticks(np.arange(0, 1020, 200))\n",
    "plt.xlim([0, 1020])\n",
    "plt.yticks(np.arange(0, 0.8, 0.1))\n",
    "plt.ylim([-0.05, 0.55])\n",
    "plt.xticks(np.arange(0, 1020, 200))\n",
    "ax.tick_params(axis = 'both', which = 'major', labelsize = 30, width=2, length=6)\n",
    "\n",
    "plt.legend(loc = 'upper right', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
