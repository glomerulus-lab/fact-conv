{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f3a63-70d9-4ced-82b6-768b46635f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, makedirs\n",
    "from os.path import join, abspath, exists\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from src.data.load_dataset import load_kmnist\n",
    "from src.models.networks import V1_mnist_RFNet, classical_RFNet\n",
    "from src.models.utils import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df376900-c1d1-44d9-80b8-8084c6de9cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = abspath(join(getcwd(), '../../'))\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e487c-72e1-4564-b9c7-611d3a11d969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "train_batch_size, train_percentage = 256, 0.999\n",
    "train_loader, val_loader, test_loader = load_kmnist(train_batch_size, train_percentage)\n",
    "batch_len = len(train_loader)\n",
    "\n",
    "# training params\n",
    "scale = 2/784 # since we do a cholesky before generating weights\n",
    "num_epochs = 20\n",
    "num_trials = 5\n",
    "log_interval = 100\n",
    "loss_fn = F.cross_entropy\n",
    "\n",
    "# V1 params\n",
    "compatible = {'s': 5, 'f':2}\n",
    "incompatible = {'s': 0.5, 'f':0.5}\n",
    "\n",
    "# params to iterate over\n",
    "hidden_size_list = [1000]\n",
    "lr_list = [1E-4, 1E-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922eca6f-be52-498a-a1cb-3565e76fd826",
   "metadata": {},
   "source": [
    "## V1 Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce4469e-9cd5-40e7-9f81-69ebe308b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s, f = compatible['s'], compatible['f']\n",
    "v1_train_loss = {h: {lr: {'mean': [], 'std': []} for lr in lr_list} for h in hidden_size_list}\n",
    "v1_test_accuracy = {h: {lr: {'mean': [], 'std': []} for lr in lr_list} for h in hidden_size_list}\n",
    "\n",
    "for h in hidden_size_list:\n",
    "    for lr in lr_list:\n",
    "        print(h, lr)\n",
    "        train_loss = np.zeros((num_trials, len(train_loader) * num_epochs))\n",
    "        test_accuracy = np.zeros((num_trials, num_epochs))\n",
    "        for trial in range(num_trials):\n",
    "            \n",
    "            # define the model and optimizer\n",
    "            model = V1_mnist_RFNet(h, s, f, center=None, scale=scale).to(device)\n",
    "            model.v1_layer.weight.requires_grad = True\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                loss = train(log_interval, device, model, train_loader, optimizer, epoch, loss_fn, verbose=False)\n",
    "                accuracy = test(model, device, test_loader, verbose=False)\n",
    "                train_loss[trial, epoch * batch_len:(epoch+1) * batch_len] = loss\n",
    "                test_accuracy[trial, epoch] = accuracy\n",
    "            \n",
    "        # train error\n",
    "        v1_train_loss[h][lr]['mean'] = np.mean(train_loss, axis=0)\n",
    "        v1_train_loss[h][lr]['std'] = np.std(train_loss, axis=0) / np.sqrt(num_trials)\n",
    "        \n",
    "        # test error\n",
    "        v1_test_accuracy[h][lr]['mean'] = np.mean(test_accuracy, axis=0)\n",
    "        v1_test_accuracy[h][lr]['std'] = np.std(test_accuracy, axis=0) / np.sqrt(num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165fa875-c92d-46d4-8301-0fe4cb83635f",
   "metadata": {},
   "source": [
    "## Classical Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503cef4d-43e9-400f-bc94-0fc29dbb3a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_size = (1, 28, 28)\n",
    "classical_train_loss = {h: {lr: {'mean': [], 'std': []} for lr in lr_list} for h in hidden_size_list}\n",
    "classical_test_accuracy = {h: {lr: {'mean': [], 'std': []} for lr in lr_list} for h in hidden_size_list}\n",
    "\n",
    "for h in hidden_size_list:\n",
    "    for lr in lr_list:\n",
    "        print(h, lr)\n",
    "        train_loss = np.zeros((num_trials, len(train_loader) * num_epochs))\n",
    "        test_accuracy = np.zeros((num_trials, num_epochs))\n",
    "        for trial in range(num_trials):\n",
    "            \n",
    "            # define the model and optimizer\n",
    "            model = classical_RFNet(inp_size, h, scale=scale).to(device)\n",
    "            model.RF_layer.weight.requires_grad = True\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                loss = train(log_interval, device, model, train_loader, optimizer, epoch, loss_fn, verbose=False)\n",
    "                accuracy = test(model, device, test_loader, verbose=False)\n",
    "                train_loss[trial, epoch * batch_len:(epoch+1) * batch_len] = loss\n",
    "                test_accuracy[trial, epoch] = accuracy\n",
    "            \n",
    "        # train error\n",
    "        classical_train_loss[h][lr]['mean'] = np.mean(train_loss, axis=0)\n",
    "        classical_train_loss[h][lr]['std'] = np.std(train_loss, axis=0) / np.sqrt(num_trials)\n",
    "        \n",
    "        # test error\n",
    "        classical_test_accuracy[h][lr]['mean'] = np.mean(test_accuracy, axis=0)\n",
    "        classical_test_accuracy[h][lr]['std'] = np.std(test_accuracy, axis=0) / np.sqrt(num_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9eb31-481d-4562-ae27-88c264f9493e",
   "metadata": {},
   "source": [
    "## incompatible net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637c0699-a01d-4f37-8929-fb7098fa8aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s, f = incompatible['s'], incompatible['f']\n",
    "incompatible_train_loss = {h: {lr: {'mean': [], 'std': []} for lr in lr_list} for h in hidden_size_list}\n",
    "incompatible_test_accuracy = {h: {lr: {'mean': [], 'std': []} for lr in lr_list} for h in hidden_size_list}\n",
    "\n",
    "for h in hidden_size_list:\n",
    "    for lr in lr_list:\n",
    "        print(h, lr)\n",
    "        train_loss = np.zeros((num_trials, len(train_loader) * num_epochs))\n",
    "        test_accuracy = np.zeros((num_trials, num_epochs))\n",
    "        for trial in range(num_trials):\n",
    "            \n",
    "            # define the model and optimizer\n",
    "            model = V1_mnist_RFNet(h, s, f, center=None, scale=scale).to(device)\n",
    "            model.v1_layer.weight.requires_grad = True\n",
    "            optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                loss = train(log_interval, device, model, train_loader, optimizer, epoch, loss_fn, verbose=False)\n",
    "                accuracy = test(model, device, test_loader, verbose=False)\n",
    "                train_loss[trial, epoch * batch_len:(epoch+1) * batch_len] = loss\n",
    "                test_accuracy[trial, epoch] = accuracy\n",
    "            \n",
    "        # train error\n",
    "        incompatible_train_loss[h][lr]['mean'] = np.mean(train_loss, axis=0)\n",
    "        incompatible_train_loss[h][lr]['std'] = np.std(train_loss, axis=0) / np.sqrt(num_trials)\n",
    "        \n",
    "        # test error\n",
    "        incompatible_test_accuracy[h][lr]['mean'] = np.mean(test_accuracy, axis=0)\n",
    "        incompatible_test_accuracy[h][lr]['std'] = np.std(test_accuracy, axis=0) / np.sqrt(num_trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24087f-b005-446e-9138-9c2d39b37f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "s, f = compatible['s'], compatible['f']\n",
    "results = {}\n",
    "results['V1'] = {'train_loss': v1_train_loss, 'test_accuracy': v1_test_accuracy}\n",
    "results['classical'] = {'train_loss': classical_train_loss, 'test_accuracy': classical_test_accuracy}\n",
    "results['incompatible'] = {'train_loss': incompatible_train_loss, 'test_accuracy': incompatible_test_accuracy}\n",
    "\n",
    "save_dir = data_dir + '/models/results/initialize_kmnist'\n",
    "if not exists(save_dir):\n",
    "    makedirs(save_dir)\n",
    "with open(save_dir + '/clf_s=%0.2f_f=%0.2f_ADAM_torch.pickle' % (s, f), 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7a462c-2245-4bd3-969c-718b33482834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "s, f = 5, 2\n",
    "with open(save_dir + '/clf_s=%0.2f_f=%0.2f_ADAM_torch.pickle' % (s, f), 'rb') as handle:\n",
    "    results = pickle.load(handle)\n",
    "\n",
    "h, lr = 1000, 1E-1\n",
    "fig = plt.figure()\n",
    "plt.plot(results['V1']['train_loss'][h][lr]['mean'], c='#2c7fb8')\n",
    "plt.plot(results['classical']['train_loss'][h][lr]['mean'], c='#d95f02')\n",
    "# plt.plot(results['incompatible']['train_loss'][h][lr]['mean'][::235], c='#91cf60')\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Iterations')\n",
    "plt.ylabel('Train Loss')\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(100 - results['V1']['test_accuracy'][h][lr]['mean'], c='#2c7fb8')\n",
    "plt.plot(100 - results['classical']['test_accuracy'][h][lr]['mean'], c='#d95f02')\n",
    "plt.plot(100 - results['incompatible']['test_accuracy'][h][lr]['mean'], c='#91cf60')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.yticks(np.arange(0, 100, 5))\n",
    "ax.set_yticklabels(np.arange(0, 100, 5) * 0.01)\n",
    "plt.ylim([0, 25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b6cfbf-f0b5-4cb6-b8b9-5dd2fd30bcc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
