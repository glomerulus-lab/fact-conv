{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401003b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd, makedirs\n",
    "from os.path import join, abspath, exists\n",
    "\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.models.estimator import RFClassifier, relu\n",
    "from src.models.weights import V1_weights, classical_weights\n",
    "from src.data.load_dataset import load_kmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbf492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = abspath(join(getcwd(), '../../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477e04aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train_loader, val_loader, test_loader = load_kmnist()\n",
    "train, test = train_loader.dataset.dataset, test_loader.dataset\n",
    "train, train_labels = train.data.numpy(), train.targets.numpy()\n",
    "X_test, y_test = test.data.numpy(), test.targets.numpy()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train, train_labels, train_size=0.999, stratify=train_labels)\n",
    "\n",
    "\n",
    "# training params\n",
    "num_neurons = sorted(set(np.logspace(0, 3.5, 50).astype('int')))\n",
    "num_trials = 5\n",
    "nonlinearity = relu\n",
    "bias = 0\n",
    "scale = 1\n",
    "clf = LinearSVC(tol=1e-4, max_iter=1000)\n",
    "n_jobs=3\n",
    "\n",
    "# V1 params\n",
    "compatible = {'s': 5, 'f':2}\n",
    "incompatible = {'s': 0.5, 'f':0.5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21361386",
   "metadata": {},
   "source": [
    "#### V1 RFNet with optimal parameters $s=5$ and $f=2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fab856f",
   "metadata": {},
   "outputs": [],
   "source": [
    "s, f = compatible['s'], compatible['f']\n",
    "kwargs = {'size':s, 'spatial_freq':f, 'center':None, 'scale':scale}\n",
    "test_V1 = {'hidden_size': [], 'mean': [], 'std_err': []}\n",
    "\n",
    "for n in tqdm(num_neurons):\n",
    "    classifiers = [RFClassifier(n, V1_weights, bias, nonlinearity, deepcopy(clf), kwargs) for i in range(num_trials)]\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        Parallel()(delayed(RFclf.fit)(X_train, y_train) for RFclf in classifiers)\n",
    "        test_accuracy = [RFclf.score(X_test, y_test) for RFclf in classifiers]\n",
    "    \n",
    "    test_V1['mean'].append(np.mean(test_accuracy))\n",
    "    test_V1['std_err'].append(np.std(test_accuracy) / np.sqrt(num_trials))\n",
    "    test_V1['hidden_size'].append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa13d87",
   "metadata": {},
   "source": [
    "#### Classical weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'scale':scale}\n",
    "test_classical = {'hidden_size': [], 'mean': [], 'std_err': []}\n",
    "\n",
    "for n in tqdm(num_neurons):\n",
    "    classifiers = [RFClassifier(n, classical_weights, bias, nonlinearity, deepcopy(clf), kwargs) for i in range(num_trials)]\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        Parallel()(delayed(RFclf.fit)(X_train, y_train) for RFclf in classifiers)\n",
    "        test_accuracy = [RFclf.score(X_test, y_test) for RFclf in classifiers]\n",
    "        \n",
    "    test_classical['mean'].append(np.mean(test_accuracy))\n",
    "    test_classical['std_err'].append(np.std(test_accuracy) / np.sqrt(num_trials))\n",
    "    test_classical['hidden_size'].append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c59af5f",
   "metadata": {},
   "source": [
    "#### Incompatible RFNet with parameters $s=0.5$ and $f=0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577e11b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "s, f = incompatible['s'], incompatible['f']\n",
    "kwargs = {'size':s, 'spatial_freq':f, 'center':None, 'scale':scale}\n",
    "test_incompatible = {'hidden_size': [], 'mean': [], 'std_err': []}\n",
    "\n",
    "for n in tqdm(num_neurons):\n",
    "    classifiers = [RFClassifier(n, V1_weights, bias, nonlinearity, deepcopy(clf), kwargs) for i in range(num_trials)]\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        Parallel()(delayed(RFclf.fit)(X_train, y_train) for RFclf in classifiers)\n",
    "        test_accuracy = [RFclf.score(X_test, y_test) for RFclf in classifiers]\n",
    "    \n",
    "    test_incompatible['mean'].append(np.mean(test_accuracy))\n",
    "    test_incompatible['std_err'].append(np.std(test_accuracy) / np.sqrt(num_trials))\n",
    "    test_incompatible['hidden_size'].append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762462b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "s, f = compatible['s'], compatible['f']\n",
    "test = {'V1': test_V1, 'classical': test_classical, 'incompatible': test_incompatible}\n",
    "save_dir = data_dir + '/models/results/kmnist_clf'\n",
    "if not exists(save_dir):\n",
    "    makedirs(save_dir)\n",
    "with open(save_dir + '/kmnist_clf_s=%0.2f_f=%0.2f_estimator.pickle' % (s, f), 'wb') as handle:\n",
    "    pickle.dump(test, handle, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8883c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "compatible = {'s': 5, 'f':2}\n",
    "s, f = compatible['s'], compatible['f']\n",
    "with open(save_dir + '/kmnist_clf_s=%0.2f_f=%0.2f_estimator.pickle' % (s, f), 'rb') as file:\n",
    "    results = pickle.load(file) \n",
    "\n",
    "fig = plt.figure()\n",
    "plt.semilogy(results['V1']['hidden_size'], 1 - np.array(results['V1']['mean']), '-', c='#2c7fb8')\n",
    "plt.semilogy(results['classical']['hidden_size'], 1 - np.array(results['classical']['mean']), c='#d95f02')\n",
    "plt.semilogy(results['incompatible']['hidden_size'], 1 - np.array(results['incompatible']['mean']), c='#91cf60')\n",
    "# plt.xlim([0, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb377c4-9f96-48b9-b5ef-9443a599e99b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
