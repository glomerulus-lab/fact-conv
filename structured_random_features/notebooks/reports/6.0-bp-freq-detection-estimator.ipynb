{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a8514a-b907-4a08-97be-0ac63ced049e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd\n",
    "from os.path import abspath, join\n",
    "\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.load_dataset import generate_frequency_detection\n",
    "from src.models.estimator import RFClassifier, relu\n",
    "from src.models.weights import sensilla_weights, classical_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d698503-ff8c-4e1e-9546-567966449991",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = abspath(join(getcwd(), '../../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f37c4c6-9f26-4dc8-8b6b-de3eb93597f7",
   "metadata": {},
   "source": [
    "#### Time-series of $0.1$s sampled at $2000$ Hz with $f_1=50$ Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1869a583-35d4-46db-a0a8-9ff26e354eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "num_samples, sampling_rate, duration, freq, snr, seed = 7000, 2000, 0.1, 50, 0.8, 5\n",
    "X, y = generate_frequency_detection(num_samples, sampling_rate, freq, duration, snr, seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y)\n",
    "\n",
    "# params\n",
    "num_neurons = sorted(set(np.logspace(0, 3, 50).astype('int')))\n",
    "num_trials = 5\n",
    "nonlinearity = relu\n",
    "bias = 0\n",
    "scale = 1\n",
    "clf = LinearSVC(tol=1e-4, max_iter=1000)\n",
    "n_jobs=6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43421ed5-8bab-41bb-88ab-77f14d66f63f",
   "metadata": {},
   "source": [
    "#### Mechanosensory weights with $f_{lo}=10$Hz, $f_{hi}=60$Hz, and $\\gamma=0.05$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57ee1c3-970f-44fe-a561-3500aa3f1693",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'sampling_rate':sampling_rate, 'duration': duration, 'lowcut':10, 'highcut':60, 'decay_coef':0.05, 'scale': scale}\n",
    "test_sensilla = {'hidden_size': [], 'mean': [], 'std_err': []}\n",
    "\n",
    "for n in tqdm(num_neurons):\n",
    "    # declare classifier, fit in parallel, and compute output score\n",
    "    classifiers = [RFClassifier(n, sensilla_weights, bias, nonlinearity, deepcopy(clf), kwargs) for i in range(num_trials)]\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        Parallel()(delayed(RFclf.fit)(X_train, y_train) for RFclf in classifiers)\n",
    "        test_accuracy = [RFclf.score(X_test, y_test) for RFclf in classifiers]\n",
    "    test_sensilla['mean'].append(np.mean(test_accuracy))\n",
    "    test_sensilla['std_err'].append(np.std(test_accuracy) / np.sqrt(num_trials))\n",
    "    test_sensilla['hidden_size'].append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb17c05-4941-4f48-94f7-63243b4627c0",
   "metadata": {},
   "source": [
    "#### Classical weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b9685-bac6-4245-a3a8-839f34663307",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'scale':scale}\n",
    "test_classical = {'hidden_size': [], 'mean': [], 'std_err': []}\n",
    "\n",
    "for n in tqdm(num_neurons):\n",
    "    # declare classifier, fit in parallel, and compute accuracy\n",
    "    classifiers = [RFClassifier(n, classical_weights, bias, nonlinearity, deepcopy(clf), kwargs) for i in range(num_trials)]\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        Parallel()(delayed(RFclf.fit)(X_train, y_train) for RFclf in classifiers)\n",
    "        test_accuracy = [RFclf.score(X_test, y_test) for RFclf in classifiers]\n",
    "    test_classical['mean'].append(np.mean(test_accuracy))\n",
    "    test_classical['std_err'].append(np.std(test_accuracy) / np.sqrt(num_trials))\n",
    "    test_classical['hidden_size'].append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f3e676-7ef8-4595-a6cf-d9f326fc890a",
   "metadata": {},
   "source": [
    "#### Incompatible weights with $f_{lo}=10$Hz, $f_{hi}=40$Hz, and $\\gamma=0.05$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a604ec0-8467-49da-bcc2-9dcee2d88849",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'sampling_rate':sampling_rate, 'duration': duration, 'lowcut':10, 'highcut':40, 'decay_coef':0.05, 'scale': scale}\n",
    "test_incompatible = {'hidden_size': [], 'mean': [], 'std_err': []}\n",
    "\n",
    "for n in tqdm(num_neurons):\n",
    "    # declare classifier, fit in parallel, and compute output score\n",
    "    classifiers = [RFClassifier(n, sensilla_weights, bias, nonlinearity, deepcopy(clf), kwargs) for i in range(num_trials)]\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        Parallel()(delayed(RFclf.fit)(X_train, y_train) for RFclf in classifiers)\n",
    "        test_accuracy = [RFclf.score(X_test, y_test) for RFclf in classifiers]\n",
    "    test_incompatible['mean'].append(np.mean(test_accuracy))\n",
    "    test_incompatible['std_err'].append(np.std(test_accuracy) / np.sqrt(num_trials))\n",
    "    test_incompatible['hidden_size'].append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf0f149-cc00-4530-a081-ceef1fa1f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "test = {'sensilla': test_sensilla, 'classical': test_classical, 'incompatible': test_incompatible}\n",
    "save_dir = data_dir + '/models/results/freq_detection'\n",
    "if not path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "with open(save_dir + '/freq_detection_sensilla_estimator.pickle', 'wb') as file:\n",
    "    pickle.dump(results, file, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00cc270-4fb4-428b-bb05-5602ae0715aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
