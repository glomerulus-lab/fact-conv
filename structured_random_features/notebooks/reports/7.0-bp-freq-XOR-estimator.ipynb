{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ad40a1-43c3-4551-85d0-a73c0e63fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import getcwd\n",
    "from os.path import abspath, join\n",
    "\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.data.load_dataset import generate_frequency_XOR\n",
    "from src.models.estimator import RFClassifier, relu\n",
    "from src.models.weights import sensilla_weights, classical_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff4942-7780-4693-be5a-dafaf07c7cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = abspath(join(getcwd(), '../../'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930fb22-cd66-41fb-aaf1-402c71fc4339",
   "metadata": {},
   "source": [
    "#### Time-series of $0.1$s sampled at $2000$ Hz with $f_1=50$ Hz and $f_2=80$ Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be37ffa4-086d-4155-9519-034e0f267b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples, sampling_rate, duration, freq1, freq2, snr, seed = 7000, 2000, 0.1, 50, 80, 0.8, 5\n",
    "X, y = generate_frequency_XOR(num_samples, sampling_rate, freq1, freq2, duration, snr, seed=None, shuffle=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y)\n",
    "\n",
    "# params\n",
    "num_neurons = sorted(set(np.logspace(0, 3, 50).astype('int')))\n",
    "num_trials = 5\n",
    "nonlinearity = relu\n",
    "bias = 0\n",
    "scale = 1\n",
    "clf = LinearSVC(tol=1e-4, max_iter=1000)\n",
    "n_jobs=6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c49a555-c1c0-4fcb-be21-7bfce4171651",
   "metadata": {},
   "source": [
    "#### Mechanosensory weights with $f_{lo}=50$Hz, $f_{hi}=90$Hz, and $\\gamma=0.04$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec24b9-64b7-49d8-80ea-d6aca9200aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'sampling_rate':sampling_rate, 'duration': duration, 'lowcut':50, 'highcut':90, 'decay_coef':0.04, 'scale': scale}\n",
    "test_sensilla = {'hidden_size': [], 'mean': [], 'std_err': []}\n",
    "\n",
    "for n in tqdm(num_neurons):\n",
    "    # declare classifier, fit in parallel, and compute output score\n",
    "    classifiers = [RFClassifier(n, sensilla_weights, bias, nonlinearity, deepcopy(clf), kwargs) for i in range(num_trials)]\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        Parallel()(delayed(RFclf.fit)(X_train, y_train) for RFclf in classifiers)\n",
    "        test_accuracy = [RFclf.score(X_test, y_test) for RFclf in classifiers]\n",
    "    test_sensilla['mean'].append(np.mean(test_accuracy))\n",
    "    test_sensilla['std_err'].append(np.std(test_accuracy) / np.sqrt(num_trials))\n",
    "    test_sensilla['hidden_size'].append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea09a1f-db2c-42e8-9ce7-95c7f0688dfd",
   "metadata": {},
   "source": [
    "#### Classical weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14580c8-5f00-4c5e-9b14-dd685fa08d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'scale':scale}\n",
    "test_classical = {'hidden_size': [], 'mean': [], 'std_err': []}\n",
    "\n",
    "for n in tqdm(num_neurons):\n",
    "    # declare classifier, fit in parallel, and compute accuracy\n",
    "    classifiers = [RFClassifier(n, classical_weights, bias, nonlinearity, deepcopy(clf), kwargs) for i in range(num_trials)]\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        Parallel()(delayed(RFclf.fit)(X_train, y_train) for RFclf in classifiers)\n",
    "        test_accuracy = [RFclf.score(X_test, y_test) for RFclf in classifiers]\n",
    "    test_classical['mean'].append(np.mean(test_accuracy))\n",
    "    test_classical['std_err'].append(np.std(test_accuracy) / np.sqrt(num_trials))\n",
    "    test_classical['hidden_size'].append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b6ffc1-18b2-49db-8706-19cd292560d3",
   "metadata": {},
   "source": [
    "#### Incompatible weights with $f_{lo}=10$Hz, $f_{hi}=60$Hz, and $\\gamma=0.04$s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f31bdfc-2fbe-463a-89da-9e0db3d05f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'sampling_rate':sampling_rate, 'duration': duration, 'lowcut':10, 'highcut':60, 'decay_coef':0.04, 'scale': scale}\n",
    "test_incompatible = {'hidden_size': [], 'mean': [], 'std_err': []}\n",
    "\n",
    "for n in tqdm(num_neurons):\n",
    "    # declare classifier, fit in parallel, and compute output score\n",
    "    classifiers = [RFClassifier(n, sensilla_weights, bias, nonlinearity, deepcopy(clf), kwargs) for i in range(num_trials)]\n",
    "    with parallel_backend('threading', n_jobs=n_jobs):\n",
    "        Parallel()(delayed(RFclf.fit)(X_train, y_train) for RFclf in classifiers)\n",
    "        test_accuracy = [RFclf.score(X_test, y_test) for RFclf in classifiers]\n",
    "    test_incompatible['mean'].append(np.mean(test_accuracy))\n",
    "    test_incompatible['std_err'].append(np.std(test_accuracy) / np.sqrt(num_trials))\n",
    "    test_incompatible['hidden_size'].append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5837da-ef17-4298-a132-236ceaa43e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "test = {'sensilla': test_sensilla, 'classical': test_classical, 'incompatible': test_incompatible}\n",
    "save_dir = data_dir + '/models/results/freq_XOR'\n",
    "if not path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "with open(save_dir + '/freq_XOR_sensilla_estimator.pickle', 'wb') as handle:\n",
    "    pickle.dump(test, handle, protocol=pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a8723-26f5-410f-9d01-038822c15d6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
