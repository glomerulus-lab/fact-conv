{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-cVPyc2o1X3l"
   },
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aOfsbJD8j8ug",
    "outputId": "3bd0f7da-d236-4df4-91ad-da07e4066642"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'robustbench'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/research/harris/vivian/v1-models/V1-models/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mV1_models\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrobustbench\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'robustbench'"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "sys.path.insert(0, '/research/harris/vivian/v1-models/V1-models/')\n",
    "import V1_models\n",
    "import robustbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hpBvSIJr0-Rg"
   },
   "source": [
    "First let's enable GPU support in Colab (*Runtime -> Change runtime type -> Hardware accelerator -> GPU*). \n",
    "\n",
    "Now let's try to load CIFAR-10 and one of the most robust CIFAR-10 models from [Unlabeled Data Improves Adversarial Robustness](https://arxiv.org/abs/1905.13736) \n",
    "that achieves 59.53% robust accuracy evaluated with AutoAttack under Linf epsilon of 8/255 on 10k points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 117,
     "referenced_widgets": [
      "1a9ae6dc45d4468e88d001895dc44a8e",
      "3c942bdb129b46d190370728e70ad966",
      "4e1b7854c8054d37841f3d5637475e3c",
      "761c61be017649d6bb92b4dfc722d063",
      "d94e5805ae2e48578f2612c2dcf54732",
      "6b84b34f9c5d4483b896f22cc03d6a13",
      "07230b34d840433995a64b56b1a5c785",
      "ec23b4cafba54aea867dc1019907a8ed",
      "fcd1facbe4e94aafba883e6bf748b534",
      "767fe558952f44c9961d47e11a4493e6",
      "dca24049fbeb42dab3f22d445780a07e"
     ]
    },
    "id": "HbQj0OdMkaXA",
    "outputId": "77fdfdc4-6b1e-42c7-9795-5ade15c32814",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'robustbench'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrobustbench\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_cifar10\n\u001b[1;32m      2\u001b[0m x_test, y_test \u001b[38;5;241m=\u001b[39m load_cifar10(n_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrobustbench\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_model\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'robustbench'"
     ]
    }
   ],
   "source": [
    "from robustbench.data import load_cifar10\n",
    "x_test, y_test = load_cifar10(n_examples=50)\n",
    "\n",
    "from robustbench.utils import load_model\n",
    "carmon = load_model(model_name='Carmon2019Unlabeled', threat_model='Linf')\n",
    "engstrom = load_model(model_name='Engstrom2019Robustness', thread_model='Linf')\n",
    "v1 = V1_models.BN_V1_V1_LinearLayer_CIFAR10(100, 2, 0.1, 1, True)\n",
    "gaussian = control_models.Gaussian_CIFAR10(100, scale=1, bias=True, seed=None)\n",
    "uniform = control_models.Uniform_CIFAR10(100, bias=True, seed=None)\n",
    "v1.load_state_dict(torch.load(\"/research/harris/vivian/v1-models/saved-models/CIFAR10/BN_V1_V1_Linear_bias_true/trial_1/model.pt\", map_location=device))\n",
    "gaussian.load_state_dict(torch.load(\"/research/harris/vivian/v1-models/saved-models/CIFAR10/Gaussian_Control_bias_true/trial_1/model.pt\", map_location=device))\n",
    "uniform.load_state_dict(torch.load(\"/research/harris/vivian/v1-models/saved-models/CIFAR10/Uniform_Control_bias_true/trial_1/model.pt\", map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFzb8RE-2bnW"
   },
   "source": [
    "For other models available in the **Model Zoo**, see the model IDs in [this table](https://github.com/AdvBench/advbench#model-zoo-list-of-models)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONmXzKqvAmWX"
   },
   "source": [
    "## Evaluate your favourite attack from FoolBox\n",
    "\n",
    "Let's try to evaluate the robustness of this model. One can use any favourite library for this. For example, [FoolBox](https://github.com/bethgelab/foolbox) is a well-established library that implements many different attacks. We can start from a simple PGD attack and evaluate it on 50 points to illustrate how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2xkdMSFVAlVc",
    "outputId": "31971916-798c-4ce5-b7d1-69f6a03a65a9"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfoolbox\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfb\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_fb \u001b[38;5;241m=\u001b[39m fb\u001b[38;5;241m.\u001b[39mPyTorchModel(model, bounds\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m----> 5\u001b[0m _, advs, success \u001b[38;5;241m=\u001b[39m fb\u001b[38;5;241m.\u001b[39mattacks\u001b[38;5;241m.\u001b[39mLinfPGD(rel_stepsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)(model_fb, \u001b[43mx_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m, y_test\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m), epsilons\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m8\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRobust accuracy: \u001b[39m\u001b[38;5;132;01m{:.1%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m success\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mmean()))\n",
      "File \u001b[0;32m~/anaconda3/envs/random_features/lib/python3.8/site-packages/torch/cuda/__init__.py:217\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# This function throws if there's a driver initialization error, no GPUs\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;66;03m# are found or any other error occurs\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    221\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx"
     ]
    }
   ],
   "source": [
    "#!pip install -q foolbox  # produces 2 incompatibility messages, but they can be just ignored\n",
    "import foolbox as fb\n",
    "\n",
    "model_fb = fb.PyTorchModel(model, bounds=(0, 1))\n",
    "_, advs, success = fb.attacks.LinfPGD(rel_stepsize=0.1, steps=20)(model_fb, x_test.to('cuda:0'), y_test.to('cuda:0'), epsilons=[8/255])\n",
    "print('Robust accuracy: {:.1%}'.format(1 - success.float().mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "clL96DX41sG3"
   },
   "source": [
    "## AutoAttack evaluation\n",
    "\n",
    "Wonderful! Can we do better with a more accurate attack?\n",
    "\n",
    "Let's try to evaluate its robustness with a cheap version [AutoAttack](https://arxiv.org/abs/2003.01690) from \n",
    "ICML 2020 with 2/4 attacks (only APGD-CE and APGD-DLR) and again on 50 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YLGmSORskSW0",
    "outputId": "b7985a27-48ca-480f-a067-42744627dd5c"
   },
   "outputs": [],
   "source": [
    "#!pip install -q git+https://github.com/fra31/auto-attack\n",
    "from autoattack import AutoAttack\n",
    "\n",
    "adversary = AutoAttack(model, norm='Linf', eps=8/255, version='custom', attacks_to_run=['apgd-ce', 'apgd-dlr'])\n",
    "adversary.apgd.n_restarts = 1\n",
    "x_adv = adversary.run_standard_evaluation(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MyAY3N117zx"
   },
   "source": [
    "Note that for our standardized evaluation of Linf-robustness we use the *full* version of AutoAttack which is slower but \n",
    "more accurate (for that just use `adversary = AutoAttack(model, norm='Linf', eps=8/255)`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itlePRumDopw"
   },
   "source": [
    "## Common corruptions\n",
    "\n",
    "What about other types of perturbations? Is Lp-robustness useful there? We can evaluate the available models on more general perturbations. For example, let's take images corrupted by *fog* perturbations from [CIFAR-10-C](https://github.com/hendrycks/robustness) with the highest level of severity (5). Are different Linf robust models perform better on them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WjdKgoW27YRn",
    "outputId": "6bdfdb66-0d23-4bc1-f1cf-3081cdd2f214"
   },
   "outputs": [],
   "source": [
    "from robustbench.data import load_cifar10c\n",
    "from robustbench.utils import clean_accuracy\n",
    "\n",
    "corruptions = ['fog']\n",
    "x_test, y_test = load_cifar10c(n_examples=1000, corruptions=corruptions, severity=5)   \n",
    "\n",
    "for model_name in ['Standard', 'Engstrom2019Robustness', 'Rice2020Overfitting', 'Carmon2019Unlabeled']:\n",
    "  model = load_model(model_name)\n",
    "  acc = clean_accuracy(model, x_test, y_test)\n",
    "  print('Model: {}, CIFAR-10-C accuracy: {:.1%}'.format(model_name, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DZWvfw2WOKKv"
   },
   "source": [
    "As we can see, **all** these Linf robust models perform considerably worse than the standard model on this type of corruptions. \n",
    "This curious phenomenon was first noticed in [Adversarial Examples Are a Natural Consequence of Test Error in Noise](https://arxiv.org/abs/1901.10513) and explained from the frequency perspective in [A Fourier Perspective on Model Robustness in Computer Vision](https://arxiv.org/abs/1906.08988). \n",
    "\n",
    "However, on average adversarial training *does* help on CIFAR-10-C. One can check this easily by loading all types of corruptions via `load_cifar10c(n_examples=1000, severity=5)`, and repeating evaluation on them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2SpVla4aTOj"
   },
   "source": [
    "## Concluding remarks\n",
    "We hope that having a *simple* and *unified* access to an up-to-date list of the most robust models will facilitate new insights about benefits and tradeoffs in robustness with respect to different types of perturbations.\n",
    "\n",
    "Feel free to contribute a new interesting dataset or analysis with novel insights! We will be happy to include it in the repository."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07230b34d840433995a64b56b1a5c785": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a9ae6dc45d4468e88d001895dc44a8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4e1b7854c8054d37841f3d5637475e3c",
       "IPY_MODEL_761c61be017649d6bb92b4dfc722d063",
       "IPY_MODEL_d94e5805ae2e48578f2612c2dcf54732"
      ],
      "layout": "IPY_MODEL_3c942bdb129b46d190370728e70ad966"
     }
    },
    "3c942bdb129b46d190370728e70ad966": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4e1b7854c8054d37841f3d5637475e3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07230b34d840433995a64b56b1a5c785",
      "placeholder": "​",
      "style": "IPY_MODEL_6b84b34f9c5d4483b896f22cc03d6a13",
      "value": ""
     }
    },
    "6b84b34f9c5d4483b896f22cc03d6a13": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "761c61be017649d6bb92b4dfc722d063": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcd1facbe4e94aafba883e6bf748b534",
      "max": 170498071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ec23b4cafba54aea867dc1019907a8ed",
      "value": 170498071
     }
    },
    "767fe558952f44c9961d47e11a4493e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d94e5805ae2e48578f2612c2dcf54732": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dca24049fbeb42dab3f22d445780a07e",
      "placeholder": "​",
      "style": "IPY_MODEL_767fe558952f44c9961d47e11a4493e6",
      "value": " 170499072/? [00:02&lt;00:00, 78220638.77it/s]"
     }
    },
    "dca24049fbeb42dab3f22d445780a07e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ec23b4cafba54aea867dc1019907a8ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fcd1facbe4e94aafba883e6bf748b534": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
